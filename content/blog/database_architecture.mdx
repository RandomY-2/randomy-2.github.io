---
slug: duckdb-architecture
title: "Dissecting DuckDB: A Code-Level Tour of Modern Database Architecture"
date: "2025-06-28"
description: "A deep dive into what components a modern database system has, using DuckDB as an example."
tags: [databases, duckdb, architecture, system design, sql]
---

## Overview of a Modern Database Pipeline

Modern databases share a familiar, *compiler-like* pipeline: SQL text enters on
one end, typed tuples shoot out the other. The CMU 15-445 diagram
([source](https://15445.courses.cs.cmu.edu/fall2023/notes/14-optimization1.pdf)) below captures
those stages at a glance.

> **TL;DR**
> SQL Query → Parsing → Binding → Logical Planning → Optimization → Physical Planning → Execution.

![Figure 1: DuckDB architecture, annotated.](/figures/database_architecture.png)

- **SQL Query** – the raw text sent by an application
- **Parsing** – tokenizes the SQL and builds an abstract syntax tree
- **Binding** – resolves table, column, and function names against the catalog and assigns types
- **Logical Planning** – converts the bound AST into relational-algebra operators
- **Optimization** – rewrites and reorders the logical plan to minimize cost
- **Physical Planning** – picks concrete algorithms (hash join, vectorized scan, etc.) and a processing order
- **Execution** – runs the physical operators, streaming result tuples back to the client

In this article we use **DuckDB**—an embedded, in-process analytical engine—as our running example.
As DuckDB original demo [paper](https://mytherin.github.io/papers/2019-duckdbdemo.pdf) described it,
DuckDB

>follow the “textbook” separation of components: Parser, logical planner, optimizer,
physical planner, execution engine

We will super-impose the CMU diagram with real entry points in DuckDB codebase as well as snippets
from DuckDB paper so you can follow every phase directly in your editor. However, DuckDB’s code base is big.
Covering every detail of DuckDB would take a book. Instead, this post acts as a map: for each stage,
the key entry functions are provided. From there you can wander as deep as your curiosity takes you.

---

## High‑Level Code Overview


The quickest way to grasp DuckDB’s execution flow is to start with the `ClientContext::Query` entry point
([source](https://github.com/duckdb/duckdb/blob/3524fe07f7c8248ec6932c40873ecb148dfc50bc/src/main/client_context.cpp#L955)).
This method wires together parsing, binding, planning, optimization, and execution; the key sections are
annotated in-line and referenced throughout the walkthrough.

(Relevant lines are commented below.)

```cpp
unique_ptr<QueryResult> ClientContext::Query(const string &query, bool allow_stream_result) {
	auto lock = LockContext();

	ErrorData error;

	/*
	 * ///////////////////////////////////////////////////////
	 * ///////////////// Parsing Logic ///////////////////////
	 * ///////////////////////////////////////////////////////
	 */
	vector<unique_ptr<SQLStatement>> statements;
	if (!ParseStatements(*lock, query, statements, error)) {
		return ErrorResult<MaterializedQueryResult>(std::move(error), query);
	}
	if (statements.empty()) {
		// no statements, return empty successful result
		StatementProperties properties;
		vector<string> names;
		auto collection = make_uniq<ColumnDataCollection>(Allocator::DefaultAllocator());
		return make_uniq<MaterializedQueryResult>(StatementType::INVALID_STATEMENT, properties, std::move(names),
		                                          std::move(collection), GetClientProperties());
	}

	unique_ptr<QueryResult> result;
	optional_ptr<QueryResult> last_result;
	bool last_had_result = false;

	for (idx_t i = 0; i < statements.size(); i++) {
		auto &statement = statements[i];
		bool is_last_statement = i + 1 == statements.size();

		/*
		 * ///////////////////////////////////////////////////////
		 * PendingQueryInternal will create query plan and optimize
		 * (Binding / Logic Planning / Optimization / Physical Planning)
		 * ///////////////////////////////////////////////////////
		 */
		PendingQueryParameters parameters;
		parameters.allow_stream_result = allow_stream_result && is_last_statement;
		auto pending_query = PendingQueryInternal(*lock, std::move(statement), parameters);
		auto has_result = pending_query->properties.return_type == StatementReturnType::QUERY_RESULT;
		unique_ptr<QueryResult> current_result;
		if (pending_query->HasError()) {
			current_result = ErrorResult<MaterializedQueryResult>(pending_query->GetErrorObject());
		} else {
			/*
			 * /////////////////////////////////////////////////////////
			 * ///////////////// Execution Logic ///////////////////////
			 * /////////////////////////////////////////////////////////
			 */
			current_result = ExecutePendingQueryInternal(*lock, *pending_query);
		}
		// now append the result to the list of results
		if (!last_result || !last_had_result) {
			// first result of the query
			result = std::move(current_result);
			last_result = result.get();
			last_had_result = has_result;
		} else {
			// later results; attach to the result chain
			// but only if there is a result
			if (!has_result) {
				continue;
			}
			last_result->next = std::move(current_result);
			last_result = last_result->next.get();
		}
		D_ASSERT(last_result);
		if (last_result->HasError()) {
			// Reset the interrupted flag, this was set by the task that found the error
			// Next statements should not be bothered by that interruption
			interrupted = false;
			break;
		}
	}
	return result;
}
```

---

## Parsing

Before the engine can reason about a query it needs syntax.  DuckDB piggy‑backs on the proven Postgres parser,
then immediately converts the Postgres nodes into its own C++ AST to avoid leaking PG structs all over the code base.

As shown above, the entry point for DuckDB parsing logic is `ClientContext::ParseStatements`
([code](https://github.com/duckdb/duckdb/blob/0069af20abea2660d67849257bc568570388d50c/src/main/client_context.cpp#L630))

```cpp
vector<unique_ptr<SQLStatement>> ClientContext::ParseStatements(const string &query) {
	auto lock = LockContext();
	return ParseStatementsInternal(*lock, query);
}

vector<unique_ptr<SQLStatement>> ClientContext::ParseStatementsInternal(ClientContextLock &lock, const string &query) {
	Parser parser(GetParserOptions());
	parser.ParseQuery(query);

	PragmaHandler handler(*this);
	handler.HandlePragmaStatements(lock, parser.statements);

	return std::move(parser.statements);
}
```

DuckDB parser code lives in [`src/parser/`](https://github.com/duckdb/duckdb/tree/main/src/parser) module, and
the entry point is [`Parser::ParseQuery`](https://github.com/duckdb/duckdb/blob/main/src/parser/parser.cpp#L191).
DuckDB uses Postgres parser to parse the SQL text and, if successfully parsed, transforms the Postgres parse tree into
DuckDB's own AST (`SQLStatements`).

As DuckDB [paper](https://mytherin.github.io/papers/2019-duckdbdemo.pdf) described it:

>The SQL parser is derived from Postgres’ SQL parser that
has been stripped down as much as possible [2]. This has
the advantage of providing DuckDB with a full-featured and
stable parser to handle one of the most volatile form of its
input, SQL queries. The parser takes a SQL query string as
input and returns a parse tree of C structures. This parse tree
is then immediately transformed into our own parse tree of
C++ classes to limit the reach of Postgres’ data structures.
This parse tree consists of statements (e.g. SELECT, INSERT
etc.) and expressions (e.g. SUM(a)+1).

```cpp
void Parser::ParseQuery(const string &query) {
	.....

	/*
	 * //////////////////// Main Logic ////////////////////
	 */
	{
		PostgresParser::SetPreserveIdentifierCase(options.preserve_identifier_case);
		bool parsing_succeed = false;
		// Creating a new scope to prevent multiple PostgresParser destructors being called
		// which led to some memory issues
		{
			PostgresParser parser;
			parser.Parse(query);
			if (parser.success) {
				if (!parser.parse_tree) {
					// empty statement
					return;
				}

				// if it succeeded, we transform the Postgres parse tree into a list of
				// SQLStatements
				transformer.TransformParseTree(parser.parse_tree, statements);
				parsing_succeed = true;
			} else {
				parser_error = parser.error_message;
				if (parser.error_location > 0) {
					parser_error_location = NumericCast<idx_t>(parser.error_location - 1);
				}
			}
		}
		// If DuckDB fails to parse the entire sql string, break the string down into individual statements
		// using ';' as the delimiter so that parser extensions can parse the statement
		if (parsing_succeed) {
			// no-op
			// return here would require refactoring into another function. o.w. will just no-op in order to run wrap up
			// code at the end of this function
		} else if (!options.extensions || options.extensions->empty()) {
			throw ParserException::SyntaxError(query, parser_error, parser_error_location);
		} else {
			// split sql string into statements and re-parse using extension
			...
		}
	}
	...
}
```

A few neat details:

- Extensions can hook the parser.  If the vanilla pass fails, DuckDB will re‑split the SQL string on
`;` and let extensions take another shot.

- Error handling carries the original character offset, so client libraries can point exactly at the
offending token.

After parsing SQL text using Postgres parser, DuckDB builds the DuckDB AST using
[`Transformer::TransformParseTree`](https://github.com/duckdb/duckdb/blob/main/src/parser/transformer.cpp#L28).
Internally, DuckDB uses a dynamic dispatch approach to transform each SQL node.

```cpp
bool Transformer::TransformParseTree(duckdb_libpgquery::PGList *tree, vector<unique_ptr<SQLStatement>> &statements) {
	InitializeStackCheck();
	for (auto entry = tree->head; entry != nullptr; entry = entry->next) {
		Clear();
		auto n = PGPointerCast<duckdb_libpgquery::PGNode>(entry->data.ptr_value);
		auto stmt = TransformStatement(*n);
		D_ASSERT(stmt);
		if (HasPivotEntries()) {
			stmt = CreatePivotStatement(std::move(stmt));
		}
		statements.push_back(std::move(stmt));
	}
	return true;
}

unique_ptr<SQLStatement> Transformer::TransformStatement(duckdb_libpgquery::PGNode &stmt) {
	auto result = TransformStatementInternal(stmt);
	result->n_param = ParamCount();
	if (!named_param_map.empty()) {
		// Avoid overriding a previous move with nothing
		result->named_param_map = std::move(named_param_map);
	}
	return result;
}

unique_ptr<SQLStatement> Transformer::TransformStatementInternal(duckdb_libpgquery::PGNode &stmt) {
	switch (stmt.type) {
	case duckdb_libpgquery::T_PGRawStmt: {
		auto &raw_stmt = PGCast<duckdb_libpgquery::PGRawStmt>(stmt);
		auto result = TransformStatement(*raw_stmt.stmt);
		if (result) {
			result->stmt_location = raw_stmt.stmt_location;
			result->stmt_length = raw_stmt.stmt_len;
		}
		return result;
	}
	case duckdb_libpgquery::T_PGSelectStmt:
		return TransformSelect(PGCast<duckdb_libpgquery::PGSelectStmt>(stmt));
	case duckdb_libpgquery::T_PGCreateStmt:
		return TransformCreateTable(PGCast<duckdb_libpgquery::PGCreateStmt>(stmt));
	case duckdb_libpgquery::T_PGCreateSchemaStmt:
		return TransformCreateSchema(PGCast<duckdb_libpgquery::PGCreateSchemaStmt>(stmt));
	...
	default:
		throw NotImplementedException(NodetypeToString(stmt.type));
	}
}
```

---

## Binding

Binding walks the AST, consulting the catalog to resolve every table, column, and function.
In DuckDB the binder also builds the first relational plan, so when `Planner::CreatePlan` returns
you already have a fully‑typed logical tree.

The DuckDB demo paper describes it as:

>The logical planner consists of two parts, the binder and
the plan generator. The binder resolves all expressions referring to schema objects such as tables or views with their
column names and types. The logical plan generator then
transforms the parse tree into a tree of basic logical query
operators such as scan, filter, project, etc. After the planning phase, we have a fully type-resolved logical query plan.
DuckDB keeps statistics on the stored data, and these are
propagated through the different expression trees as part of
the planning process. These statistics are used in the optimizer itself, and are also used for integer overflow prevention
by upgrading types when required.

As mentioned above, DuckDB will bind, create query plan, and optimize inside
[`ClientContext::PendingQueryInternal`](https://github.com/jensenojs/duckdb/blob/main/src/main/client_context.cpp#L1083).
There are several call stacks:

```
ClientContext::PendingQueryInternal
-> ClientContext::PendingStatementOrPreparedStatementInternal
-> ClientContext::CreatePreparedStatement
-> ClientContext::CreatePreparedStatementInternal (important one)
```

[`ClientContext::CreatePreparedStatementInternal`](https://github.com/jensenojs/duckdb/blob/main/src/main/client_context.cpp#L354)
performs binding/logical planning/optimizing/physical planning.

(Relevant lines are commented below.)

```cpp
shared_ptr<PreparedStatementData>
ClientContext::CreatePreparedStatementInternal(ClientContextLock &lock, const string &query,
                                               unique_ptr<SQLStatement> statement,
                                               optional_ptr<case_insensitive_map_t<BoundParameterData>> values) {
	StatementType statement_type = statement->type;
	auto result = make_shared_ptr<PreparedStatementData>(statement_type);

	auto &profiler = QueryProfiler::Get(*this);
	profiler.StartQuery(query, IsExplainAnalyze(statement.get()), true);
	profiler.StartPhase(MetricsType::PLANNER);
	Planner logical_planner(*this);
	if (values) {
		auto &parameter_values = *values;
		for (auto &value : parameter_values) {
			logical_planner.parameter_data.emplace(value.first, BoundParameterData(value.second));
		}
	}

	/*
	 * ///////////////////////////////////////////////////////
	 *  CreatePlan performs both binding and logical planning
	 * ///////////////////////////////////////////////////////
	 */
	logical_planner.CreatePlan(std::move(statement));
	D_ASSERT(logical_planner.plan || !logical_planner.properties.bound_all_parameters);
	profiler.EndPhase();

	auto logical_plan = std::move(logical_planner.plan);
	// extract the result column names from the plan
	result->properties = logical_planner.properties;
	result->names = logical_planner.names;
	result->types = logical_planner.types;
	result->value_map = std::move(logical_planner.value_map);
	if (!logical_planner.properties.bound_all_parameters) {
		return result;
	}
#ifdef DEBUG
	logical_plan->Verify(*this);
#endif

    /*
	 * ///////////////////////////////////////////////////////
	 * //////////////////// Optimization /////////////////////
	 * ///////////////////////////////////////////////////////
	 */
	if (config.enable_optimizer && logical_plan->RequireOptimizer()) {
		profiler.StartPhase(MetricsType::ALL_OPTIMIZERS);
		Optimizer optimizer(*logical_planner.binder, *this);
		logical_plan = optimizer.Optimize(std::move(logical_plan));
		D_ASSERT(logical_plan);
		profiler.EndPhase();

#ifdef DEBUG
		logical_plan->Verify(*this);
#endif
	}

	/*
	 * ///////////////////////////////////////////////////////
	 * ////////////////// Physical Planning //////////////////
	 * ///////////////////////////////////////////////////////
	 */
	// Convert the logical query plan into a physical query plan.
	profiler.StartPhase(MetricsType::PHYSICAL_PLANNER);
	PhysicalPlanGenerator physical_planner(*this);
	result->physical_plan = physical_planner.Plan(std::move(logical_plan));
	profiler.EndPhase();
	D_ASSERT(result->physical_plan);
	return result;
}
```

Specifically, both Binding and Logical Planning happen inside
[`Planner::CreatePlan`](https://github.com/duckdb/duckdb/blob/main/src/planner/planner.cpp#L34).

```cpp
void Planner::CreatePlan(SQLStatement &statement) {
	...

	profiler.StartPhase(MetricsType::PLANNER_BINDING);
	binder->parameters = &bound_parameters;

	/*
	 * //////////////////////////////////////
	 * ///// Binding + Logical Planning /////
	 * //////////////////////////////////////
	 */
	auto bound_statement = binder->Bind(statement);
	profiler.EndPhase();

	...
}
```

`Planner::CreatePlan` invokes
[`Binder::Bind`](https://github.com/duckdb/duckdb/blob/3524fe07f7c8248ec6932c40873ecb148dfc50bc/src/planner/binder.cpp#L145)
method, which uses a dynamic dispatch approach to further invoke the `Binder::Bind` method for each type of SQL node.

For example, for a SELECT node, the [`Binder::Bind`](https://github.com/duckdb/duckdb/blob/3524fe07f7c8248ec6932c40873ecb148dfc50bc/src/planner/binder/statement/bind_select.cpp#L7)
method is:

```cpp
BoundStatement Binder::Bind(SelectStatement &stmt) {
	auto &properties = GetStatementProperties();
	properties.allow_stream_result = true;
	properties.return_type = StatementReturnType::QUERY_RESULT;
	return Bind(*stmt.node);
}
```

After SELECT statement-specific binding logic, the method invokes another
[`Binder::Bind`](https://github.com/duckdb/duckdb/blob/3524fe07f7c8248ec6932c40873ecb148dfc50bc/src/planner/binder.cpp#L233)
on QueryNode object, which creates the logical plan:

```cpp
BoundStatement Binder::Bind(QueryNode &node) {
	BoundStatement result;
	auto bound_node = BindNode(node);

	result.names = bound_node->names;
	result.types = bound_node->types;

	// and plan it
	result.plan = CreatePlan(*bound_node);
	return result;
}
```

---

## Logical Planning

Once bindings are resolved the planner expands each clause (FROM, WHERE, GROUP BY, …)
into a concrete LogicalOperator.  By the time you reach the root, the tree already looks very
familiar if you have ever read Volcano papers.

[`Binder::CreatePlan`](https://github.com/duckdb/duckdb/blob/b44b8f91db1523dc3fdaebbcd3213298c796115b/src/planner/binder.cpp#L378)
generates different LogicalOperators based on the query node's type.

```cpp
unique_ptr<LogicalOperator> Binder::CreatePlan(BoundQueryNode &node) {
	switch (node.type) {
	case QueryNodeType::SELECT_NODE:
		return CreatePlan(node.Cast<BoundSelectNode>());
	case QueryNodeType::SET_OPERATION_NODE:
		return CreatePlan(node.Cast<BoundSetOperationNode>());
	case QueryNodeType::RECURSIVE_CTE_NODE:
		return CreatePlan(node.Cast<BoundRecursiveCTENode>());
	case QueryNodeType::CTE_NODE:
		return CreatePlan(node.Cast<BoundCTENode>());
	default:
		throw InternalException("Unsupported bound query node type");
	}
}
```

For example, for a SELECT node,
[`Binder::CreatePlan(BoundSelectNode &statement)`](https://github.com/duckdb/duckdb/blob/a35d8b6d5ba121f2601b917e1a7732207c944ae5/src/planner/binder/query_node/plan_select_node.cpp#L18)
is called. The function further adds LogicalOperator for clauses in a SELECT statement, such as FROM, SAMPLE, WHERE, etc.

```cpp
unique_ptr<LogicalOperator> Binder::CreatePlan(BoundSelectNode &statement) {
	unique_ptr<LogicalOperator> root;

	D_ASSERT(statement.from_table);

	// plan the from clause
	root = CreatePlan(*statement.from_table);

	D_ASSERT(root);

	// plan the sample clause
	if (statement.sample_options) {
		root = make_uniq<LogicalSample>(std::move(statement.sample_options), std::move(root));
	}

  // plan the where clause
	if (statement.where_clause) {
		root = PlanFilter(std::move(statement.where_clause), std::move(root));
	}

  // plan groupby and aggregation
	if (!statement.aggregates.empty() || !statement.groups.group_expressions.empty()) {

		// groupby
		if (!statement.groups.group_expressions.empty()) {
			// visit the groups
			for (auto &group : statement.groups.group_expressions) {
				PlanSubqueries(group, root);
			}
		}

		// now visit all aggregate expressions
		for (auto &expr : statement.aggregates) {
			PlanSubqueries(expr, root);
		}

		// finally create the aggregate node with the group_index and aggregate_index as obtained from the binder
		auto aggregate = make_uniq<LogicalAggregate>(statement.group_index, statement.aggregate_index,
		                                             std::move(statement.aggregates));
		aggregate->groups = std::move(statement.groups.group_expressions);
		aggregate->groupings_index = statement.groupings_index;
		aggregate->grouping_sets = std::move(statement.groups.grouping_sets);
		aggregate->grouping_functions = std::move(statement.grouping_functions);

		aggregate->AddChild(std::move(root));
		root = std::move(aggregate);
	} else if (!statement.groups.grouping_sets.empty()) {
		// edge case: we have grouping sets but no groups or aggregates
		// this can only happen if we have e.g. select 1 from tbl group by ();
		// just output a dummy scan
		root = make_uniq_base<LogicalOperator, LogicalDummyScan>(statement.group_index);
	}

  // HAVING
	if (statement.having) {
		PlanSubqueries(statement.having, root);
		auto having = make_uniq<LogicalFilter>(std::move(statement.having));

		having->AddChild(std::move(root));
		root = std::move(having);
	}

  // plan window expression
	if (!statement.windows.empty()) {
		auto win = make_uniq<LogicalWindow>(statement.window_index);
		win->expressions = std::move(statement.windows);
		// visit the window expressions
		for (auto &expr : win->expressions) {
			PlanSubqueries(expr, root);
		}
		D_ASSERT(!win->expressions.empty());
		win->AddChild(std::move(root));
		root = std::move(win);
	}

  // plan qualify
	if (statement.qualify) {
		PlanSubqueries(statement.qualify, root);
		auto qualify = make_uniq<LogicalFilter>(std::move(statement.qualify));

		qualify->AddChild(std::move(root));
		root = std::move(qualify);
	}

  // plan unnest operations (flatten nested list-like or array-like columns
  // e.g., LIST, ARRAY, JSON into a row-wise representation)
	for (idx_t i = statement.unnests.size(); i > 0; i--) {
		auto unnest_level = i - 1;
		auto entry = statement.unnests.find(unnest_level);
		if (entry == statement.unnests.end()) {
			throw InternalException("unnests specified at level %d but none were found", unnest_level);
		}
		auto &unnest_node = entry->second;
		auto unnest = make_uniq<LogicalUnnest>(unnest_node.index);
		unnest->expressions = std::move(unnest_node.expressions);
		// visit the unnest expressions
		for (auto &expr : unnest->expressions) {
			PlanSubqueries(expr, root);
		}
		D_ASSERT(!unnest->expressions.empty());
		unnest->AddChild(std::move(root));
		root = std::move(unnest);
	}

  // SELECT subquery (i.e., SELECT a, (SELECT b FROM ...), c FROM ...)
	for (auto &expr : statement.select_list) {
		PlanSubqueries(expr, root);
	}

	auto proj = make_uniq<LogicalProjection>(statement.projection_index, std::move(statement.select_list));
	auto &projection = *proj;
	proj->AddChild(std::move(root));
	root = std::move(proj);

	// finish the plan by handling the elements of the QueryNode
	root = VisitQueryNode(statement, std::move(root));

	// add a prune node if necessary
	if (statement.need_prune) {
		D_ASSERT(root);
		vector<unique_ptr<Expression>> prune_expressions;
		for (idx_t i = 0; i < statement.column_count; i++) {
			prune_expressions.push_back(make_uniq<BoundColumnRefExpression>(
			    projection.expressions[i]->return_type, ColumnBinding(statement.projection_index, i)));
		}
		auto prune = make_uniq<LogicalProjection>(statement.prune_index, std::move(prune_expressions));
		prune->AddChild(std::move(root));
		root = std::move(prune);
	}
	return root;
}
```

---

## Optimizing

Now, we return to
[`ClientContext::CreatePreparedStatementInternal`](https://github.com/jensenojs/duckdb/blob/main/src/main/client_context.cpp#L354),
which is the entry point for DuckDB's optimization logic.
Here DuckDB diverges from heavyweight optimizers like Cascades or Calcite.
Rather than iterate rules to a fix‑point, DuckDB runs a deterministic conveyor
belt of passes—each fires once in a fixed order.

>DuckDB’s optimizer performs join order optimization using dynamic programming [7] with a greedy fallback for
complex join graphs [11]. It performs flattening of arbitrary
subqueries as described in Neumann et al. [9]. In addition,
there are a set of rewrite rules that simplify the expression
tree, by performing e.g. common subexpression elimination
and constant folding. Cardinality estimation is done using a
combination of samples and HyperLogLog. The result of this
process is the optimized logical plan for the query.

```cpp
shared_ptr<PreparedStatementData>
ClientContext::CreatePreparedStatementInternal(ClientContextLock &lock, const string &query,
                                               unique_ptr<SQLStatement> statement,
                                               optional_ptr<case_insensitive_map_t<BoundParameterData>> values) {

	...

	if (config.enable_optimizer && logical_plan->RequireOptimizer()) {
		profiler.StartPhase(MetricsType::ALL_OPTIMIZERS);
		Optimizer optimizer(*logical_planner.binder, *this);
		logical_plan = optimizer.Optimize(std::move(logical_plan));
		D_ASSERT(logical_plan);
		profiler.EndPhase();

	...
}
```

`ClientContext::CreatePreparedStatementInternal` invokes
[`Optimizer::Optimize`](https://github.com/duckdb/duckdb/blob/a35d8b6d5ba121f2601b917e1a7732207c944ae5/src/optimizer/optimizer.cpp#L270).

```cpp
unique_ptr<LogicalOperator> Optimizer::Optimize(unique_ptr<LogicalOperator> plan_p) {
	Verify(*plan_p);

	this->plan = std::move(plan_p);

	for (auto &pre_optimizer_extension : DBConfig::GetConfig(context).optimizer_extensions) {
		RunOptimizer(OptimizerType::EXTENSION, [&]() {
			OptimizerExtensionInput input {GetContext(), *this, pre_optimizer_extension.optimizer_info.get()};
			if (pre_optimizer_extension.pre_optimize_function) {
				pre_optimizer_extension.pre_optimize_function(input, plan);
			}
		});
	}

	RunBuiltInOptimizers();

	for (auto &optimizer_extension : DBConfig::GetConfig(context).optimizer_extensions) {
		RunOptimizer(OptimizerType::EXTENSION, [&]() {
			OptimizerExtensionInput input {GetContext(), *this, optimizer_extension.optimizer_info.get()};
			if (optimizer_extension.optimize_function) {
				optimizer_extension.optimize_function(input, plan);
			}
		});
	}

	Planner::VerifyPlan(context, plan);

	return std::move(plan);
}
```

which invokes [`Optimizer::RunBuiltInOptimizers`](https://github.com/duckdb/duckdb/blob/a35d8b6d5ba121f2601b917e1a7732207c944ae5/src/optimizer/optimizer.cpp#L101).

```cpp
void Optimizer::RunBuiltInOptimizers() {
	switch (plan->type) {
	case LogicalOperatorType::LOGICAL_TRANSACTION:
	case LogicalOperatorType::LOGICAL_PRAGMA:
	case LogicalOperatorType::LOGICAL_SET:
	case LogicalOperatorType::LOGICAL_UPDATE_EXTENSIONS:
	case LogicalOperatorType::LOGICAL_CREATE_SECRET:
	case LogicalOperatorType::LOGICAL_EXTENSION_OPERATOR:
		// skip optimizing simple & often-occurring plans unaffected by rewrites
		if (plan->children.empty()) {
			return;
		}
		break;
	default:
		break;
	}
	// first we perform expression rewrites using the ExpressionRewriter
	// this does not change the logical plan structure, but only simplifies the expression trees
	RunOptimizer(OptimizerType::EXPRESSION_REWRITER, [&]() { rewriter.VisitOperator(*plan); });

	// Rewrites SUM(x + C) into SUM(x) + C * COUNT(x)
	RunOptimizer(OptimizerType::SUM_REWRITER, [&]() {
		SumRewriterOptimizer optimizer(*this);
		optimizer.Optimize(plan);
	});

	// perform filter pullup
	RunOptimizer(OptimizerType::FILTER_PULLUP, [&]() {
		FilterPullup filter_pullup;
		plan = filter_pullup.Rewrite(std::move(plan));
	});

	...

	// perform join filter pushdown after the dust has settled
	RunOptimizer(OptimizerType::JOIN_FILTER_PUSHDOWN, [&]() {
		JoinFilterPushdownOptimizer join_filter_pushdown(*this);
		join_filter_pushdown.VisitOperator(*plan);
	});
}
```

DuckDB optimizer includes Rule-based Optimizations, such as
[`EXPRESSION_REWRITER`](https://github.com/duckdb/duckdb/blob/a35d8b6d5ba121f2601b917e1a7732207c944ae5/src/include/duckdb/optimizer/expression_rewriter.hpp#L19),
as well as Cost-based Optimizations, such as
[`JOIN_ORDER`](https://github.com/duckdb/duckdb/blob/a35d8b6d5ba121f2601b917e1a7732207c944ae5/src/include/duckdb/optimizer/join_order/join_order_optimizer.hpp#L26).

---

## Physical Planning

Again, we return to
[`ClientContext::CreatePreparedStatementInternal`](https://github.com/jensenojs/duckdb/blob/main/src/main/client_context.cpp#L354),
which is the entry point for DuckDB's physical planing logic.

With the logical plan polished, the PhysicalPlanGenerator swaps algebraic operators for concrete algorithms:
- Scans may become sequential, index, or parquet scans.
- Joins choose between hash, merge, nested‑loop, or even piecewise merge.
- Aggregates decide on hash vs. sort based on GROUP BY keys & memory budget.

> The physical planner transforms the logical plan into the physical plan,
selecting suitable implementations where applicable. For example, a scan may
decide to use an existing index instead of
scanning the base tables based on selectivity estimates, or
switch between a hash join or merge join depending on the
join predicates.

```cpp
shared_ptr<PreparedStatementData>
ClientContext::CreatePreparedStatementInternal(ClientContextLock &lock, const string &query,
                                               unique_ptr<SQLStatement> statement,
                                               optional_ptr<case_insensitive_map_t<BoundParameterData>> values) {

	...

	// Convert the logical query plan into a physical query plan.
	profiler.StartPhase(MetricsType::PHYSICAL_PLANNER);
	PhysicalPlanGenerator physical_planner(*this);
	result->physical_plan = physical_planner.Plan(std::move(logical_plan));
	profiler.EndPhase();
	D_ASSERT(result->physical_plan);
	return result;
}
```

The heart of DuckDB physical planning is [`PhysicalPlanGenerator::CreatePlan`](https://github.com/duckdb/duckdb/blob/32459c958ae5e1c112a02257dcc5b9f4bd59a7cc/src/execution/physical_plan_generator.cpp#L69),
which converts each LogicalOperatorType to a corresponding physical plan operator.

```cpp
PhysicalOperator &PhysicalPlanGenerator::CreatePlan(LogicalOperator &op) {
	switch (op.type) {
	case LogicalOperatorType::LOGICAL_GET:
		return CreatePlan(op.Cast<LogicalGet>());
	...
	case LogicalOperatorType::LOGICAL_EXTENSION_OPERATOR: {
		auto &extension_op = op.Cast<LogicalExtensionOperator>();
		return extension_op.CreatePlan(context, *this);
	}
	case LogicalOperatorType::LOGICAL_JOIN:
	case LogicalOperatorType::LOGICAL_DEPENDENT_JOIN:
	case LogicalOperatorType::LOGICAL_INVALID: {
		throw NotImplementedException("Unimplemented logical operator type!");
	}
	}
	throw InternalException("Physical plan generator - no plan generated");
}
```

---

## Execution

Finally, [`PendingQueryResult::ExecuteInternal`](https://github.com/duckdb/duckdb/blob/32459c958ae5e1c112a02257dcc5b9f4bd59a7cc/src/main/pending_query_result.cpp#L71).
pulls vector chunks (1 k rows by default) through the physical tree.
DuckDB calls the design Vector Volcano: same pull‑based iterator model as
classic Volcano, but each call returns a SIMD‑friendly block instead of a single tuple.

>DuckDB uses a vectorized interpreted execution engine [1].
This approach was chosen over Just-in-Time compilation
(JIT) of SQL queries [8] for portability reasons. JIT engines
depend on massive compiler libraries (e.g. LLVM) with additional transitive dependencies. DuckDB uses vectors of a
fixed maximum amount of values (1024 per default). Fixedlength types such as integers are stored as native arrays.
Variable-length values such as strings are represented as a
native array of pointers into a separate string heap. NULL
values are represented using a separate bit vector, which
is only present if NULL values appear in the vector. This
allows fast intersection of NULL vectors for binary vector
operations and avoids redundant computation. To avoid excessive shifting of data within the vectors when e.g. the data
is filtered, the vectors may have a selection vector, which is
a list of offsets into the vector stating which indices of the
vector are relevant [1]. DuckDB contains an extensive library
of vector operations that support the relational operators,
this library expands code for all supported data types using
C++ code templates.
The execution engine executes the query in a so-called
“Vector Volcano” model. Query execution commences by pulling
the first “chunk” of data from the root node of the physical
plan. A chunk is a horizontal subset of a result set, query
intermediate or base table. This node will recursively pull
chunks from child nodes, eventually arriving at a scan operator which produces chunks by reading from the persistent
tables. This continues until the chunk arriving at the root is
empty, at which point the query is completed

```cpp
unique_ptr<QueryResult> PendingQueryResult::ExecuteInternal(ClientContextLock &lock) {
	CheckExecutableInternal(lock);

	PendingExecutionResult execution_result;
	while (!IsResultReady(execution_result = ExecuteTaskInternal(lock))) {
		if (execution_result == PendingExecutionResult::BLOCKED) {
			CheckExecutableInternal(lock);
			context->WaitForTask(lock, *this);
		}
	}
	if (HasError()) {
		if (allow_stream_result) {
			return make_uniq<StreamQueryResult>(error);
		} else {
			return make_uniq<MaterializedQueryResult>(error);
		}
	}
	auto result = context->FetchResultInternal(lock, *this);
	Close();
	return result;
}
```

---

## 5  Further Reading

* [DuckDB: An Embeddable Analytical Database](https://mytherin.github.io/papers/2019-duckdbdemo.pdf)
* The [DuckDB source](https://github.com/duckdb/duckdb) (start with `src/main/client_context.cpp`)

---

Next time you run:

```sql
SELECT foo FROM bar;
```

remember the tiny journey your query takes inside the Duck!

---
